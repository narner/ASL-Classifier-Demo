# ASL Classifier Demo

This project demonstrates the usage of a CoreML model to classify American Sign-Language from a live video feed on iOS. The CoreML model was trained using CreateML on David Lee's American Sign Language Letters Dataset, which is [hosted on Roboflow](https://public.roboflow.com/object-detection/american-sign-language-letters).

![ASL Classifier Demo](https://github.com/narner/ASL-Classifier-Demo/blob/main/ASL%20CLassifier%20Demo/Documentation/ASL%20Classifier%20Demo.gif)



![ASL Classifier Demo](https://github.com/narner/ASL-Classifier-Demo/blob/main/ASL%20CLassifier%20Demo/Documentation/O-Detection.png)



![ASL Classifier Demo](https://github.com/narner/ASL-Classifier-Demo/blob/main/ASL%20CLassifier%20Demo/Documentation/L-Detection.png)



## License

The model itself is available for use under the public-domain license, as that is what the dataset it was trained on is licensed under. 

The source code is a modified version of Apple's Vision example project, [Breakfast Finder.](https://developer.apple.com/documentation/vision/recognizing_objects_in_live_capture) More information is available in the LICENSE.txt file. 




